{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import torchmetrics\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=8\n",
    "image_count=50\n",
    "img_size=512\n",
    "tf = ToTensor()\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_list=glob('../../data/segmentation/whi/test/img/*.tiff')\n",
    "test_mask_list=[f.replace('/img/', '/mask/TP_tumor/') for f in test_image_list]\n",
    "train_image_list=glob('../../data/segmentation/whi/train/img/*.tiff')\n",
    "train_mask_list=[f.replace('/img/', '/mask/TP_tumor/') for f in train_image_list]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tensor = self.img_path[idx]\n",
    "        label_tensor =  self.label[idx]\n",
    "        return image_tensor, label_tensor\n",
    "train_image=torch.zeros((len(train_image_list),3,img_size,img_size))\n",
    "train_mask=torch.zeros((len(train_image_list),1,img_size,img_size))\n",
    "test_image=torch.zeros((len(test_image_list),3,img_size,img_size))\n",
    "test_mask=torch.zeros((len(test_image_list),1,img_size,img_size))\n",
    "\n",
    "for i in tqdm(range(len(train_image_list))):\n",
    "    img=1-tf(np.array(expand2square(Image.open(train_image_list[0]),(255,255,255)).resize((img_size,img_size))))\n",
    "    msk=tf(np.array((expand2square(Image.open(train_mask_list[0]),(0,0,0)).convert('L')).resize((img_size,img_size))))\n",
    "    train_image[i]=img\n",
    "    train_mask[i]=msk\n",
    "    \n",
    "for i in tqdm(range(len(test_image_list))):\n",
    "    img=1-tf(np.array(expand2square(Image.open(test_image_list[0]),(255,255,255)).resize((img_size,img_size))))\n",
    "    msk=tf(np.array((expand2square(Image.open(test_mask_list[0]),(0,0,0)).convert('L')).resize((img_size,img_size))))\n",
    "    test_image[i]=img\n",
    "    test_mask[i]=msk\n",
    "    \n",
    "train_dataset = CustomDataset(train_image, train_mask)\n",
    "\n",
    "test_dataset = CustomDataset(test_image, test_mask)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=smp.UnetPlusPlus('efficientnet-b6').to(device)\n",
    "summary(model,(batch_size,3,img_size,img_size))\n",
    "def diceloss(pred, target):\n",
    "    smooth = 1.\n",
    "    iflat = pred.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    A_sum = torch.sum(iflat * iflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = diceloss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "MIN_loss=5000\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4)\n",
    "metrics = defaultdict(float)\n",
    "for epoch in range(100):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = calc_loss(predict, y,metrics) # cost 구함\n",
    "        acc=1-calc_loss(predict, y,metrics)\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        train.set_description(f\"epoch: {epoch+1}/{100} Step: {count+1} dice_loss : {running_loss/count:.4f} dice_score: {acc_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "#validation\n",
    "    val=tqdm(validation_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            cost = calc_loss(predict, y,metrics) # cost 구함\n",
    "            acc=1-calc_loss(predict, y,metrics)\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            val.set_description(f\"Validation epoch: {epoch+1}/{100} Step: {count+1} dice_loss : {val_running_loss/count:.4f}  dice_score: {acc_loss/count:.4f}\")\n",
    "        val_loss_list.append((val_running_loss/count))\n",
    "        val_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "        \n",
    "    if MIN_loss>(val_running_loss/count):\n",
    "        torch.save(model.state_dict(), '../../model/eff_Unet_callback.pt')\n",
    "        MIN_loss=(val_running_loss/count)\n",
    "        \n",
    "    if epoch%20==1:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(1, 2, 1) \n",
    "        plt.title('loss_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_loss_list,label='train_loss')\n",
    "        plt.plot(np.arange(epoch+1),val_loss_list,label='validation_loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        plt.title('acc_graph')\n",
    "        plt.plot(np.arange(epoch+1),train_acc_list,label='train_acc')\n",
    "        plt.plot(np.arange(epoch+1),val_acc_list,label='validation_acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.ylim([0, 1]) \n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
