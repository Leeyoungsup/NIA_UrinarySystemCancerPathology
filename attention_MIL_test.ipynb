{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import torchmetrics\n",
    "import timm\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=1\n",
    "image_count=25\n",
    "img_size=256\n",
    "tf = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_malignant_path='../../data/1-cycle_10%_초기데이터/classification/image_10_test/abnormal/*'\n",
    "test_image_normal_path='../../data/1-cycle_10%_초기데이터/classification/image_10_test/normal/*'\n",
    "test_image_in_situ_path='../../data/1-cycle_10%_초기데이터/classification/image_10_test/CLS/*'\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "\n",
    "        self.label = label_list\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tensor = torch.empty((image_count,3, img_size, img_size))\n",
    "        \n",
    "        image_file_list = glob(self.img_path[idx]+'/*.jpg')\n",
    "        image_index = torch.randint(low=0, high=len(\n",
    "            image_file_list)-1, size=(image_count,))\n",
    "        count = 0\n",
    "        for index in image_index:\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            image_tensor[count] = image\n",
    "            count += 1\n",
    "        label_tensor =  self.label[idx]\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "test_image_list = []\n",
    "test_label_list = []\n",
    "image_in_situ_list = glob(test_image_in_situ_path)\n",
    "image_in_situ_label = torch.ones(len(image_in_situ_list), 1)\n",
    "image_normal_list = glob(test_image_normal_path)\n",
    "image_normal_label = torch.zeros(len(image_normal_list), 1)\n",
    "image_abnormal_list = glob(test_image_malignant_path)\n",
    "image_abnormal_label = torch.ones(len(image_abnormal_list), 1)*2\n",
    "test_image_list.extend(image_abnormal_list)\n",
    "test_image_list.extend(image_normal_list)\n",
    "test_image_list.extend(image_in_situ_list)\n",
    "test_label_list.extend(image_abnormal_label)\n",
    "test_label_list.extend(image_normal_label)\n",
    "test_label_list.extend(image_in_situ_label)\n",
    "\n",
    "test_dataset = CustomDataset(test_image_list, F.one_hot(torch.tensor(test_label_list).to(torch.int64)))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('efficientnet_b2', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "class AttentionMILModel(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(AttentionMILModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(image_feature_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_tiles, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Flatten the inputs\n",
    "        inputs = inputs.view(-1, channels, height, width)\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size * num_tiles, 2048, 1, 1)\n",
    "        \n",
    "        # Reshape features\n",
    "        features = features.view(batch_size, num_tiles, -1)  # Shape: (batch_size, num_tiles, 2048)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(features)  # Shape: (batch_size, num_tiles, 1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)  # Normalize attention weights\n",
    "        \n",
    "        # Apply attention weights to features\n",
    "        attended_features = torch.sum(features * attention_weights, dim=1)  # Shape: (batch_size, 2048)\n",
    "        \n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(attended_features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits  \n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = AttentionMILModel(3,1408,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "summary(model,(batch_size,image_count,3,img_size,img_size))\n",
    "model.load_state_dict(torch.load('../../model/attention_MIL_eff_callback.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_y = torch.zeros((len(test_dataloader), 3)).to(device)\n",
    "total_prob = torch.zeros((len(test_dataloader), 3)).to(device)\n",
    "model.eval()\n",
    "count=0\n",
    "val_running_loss=0.0\n",
    "acc_loss=0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "        y = y.to(device).float()\n",
    "        x=x.to(device).float()\n",
    "        predict = model(x).to(device)\n",
    "        cost = F.cross_entropy(predict.softmax(dim=1), y) # cost 구함\n",
    "        acc=accuracy(predict.softmax(dim=1).argmax(dim=1),y.argmax(dim=1))\n",
    "        val_running_loss+=cost.item()\n",
    "        acc_loss+=acc\n",
    "        prob_pred = predict.softmax(dim=1)\n",
    "        total_y[count] = y.squeeze(dim=1)\n",
    "        total_prob[count] = prob_pred\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, RocCurveDisplay\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(total_y.cpu()[:, i], total_prob.cpu()[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "test_score=roc_auc_score(total_y.cpu().argmax(axis=1),total_prob.cpu(), multi_class='ovr')\n",
    "# 모든 클래스의 ROC 곡선을 그립니다.\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue', 'red', 'green']\n",
    "class1=['normal','in_situ','malignant']\n",
    "for i, color in zip(range(3), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{class1[i]} (area = {roc_auc[i]:.2f})')\n",
    "print(f'total AUC score= {test_score}')   \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=13)\n",
    "plt.ylabel('True Positive Rate',fontsize=13)\n",
    "plt.legend(loc=\"lower right\",fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "cm = confusion_matrix(total_y.cpu().argmax(axis=1),total_prob.cpu().argmax(axis=1))\n",
    "classes = ['normal','in_situ','malifnant']\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm,\n",
    "                              display_labels=classes).plot()\n",
    "f1 = f1_score(total_y.cpu().argmax(axis=1),total_prob.cpu().argmax(axis=1), average='macro')\n",
    "report = classification_report(total_y.cpu().argmax(axis=1),total_prob.cpu().argmax(axis=1))\n",
    "print(report)\n",
    "print(f'total f1-score= {f1}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
