{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image,mask):\n",
    "        self.img=image\n",
    "        self.mask=mask\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tensor=self.img[idx]\n",
    "        mask_tensor=self.mask[idx]\n",
    "        return image_tensor,mask_tensor\n",
    "    \n",
    "image_path='../../data/1-cycle_10%_초기데이터/segmentation/image/*.tiff'\n",
    "mask_path='../../data/1-cycle_10%_초기데이터/segmentation/mask/*.tiff'\n",
    "train_image_list=glob(image_path)[:100]\n",
    "train_mask_list=glob(mask_path)[:100]\n",
    "test_image_list=glob(image_path)[100:]\n",
    "test_mask_list=glob(mask_path)[100:]\n",
    "\n",
    "train_tensor_image=torch.empty(len(train_image_list),3,512,512)\n",
    "train_tensor_mask=torch.empty(len(train_mask_list),1,512,512)\n",
    "tf = ToTensor()\n",
    "for i in range(len(train_image_list)):\n",
    "    image=tf(Image.open(train_image_list[i]))/255\n",
    "    mask=tf(Image.open(train_mask_list[i]).convert(\"L\"))/255\n",
    "    train_tensor_image[i]=image\n",
    "    train_tensor_mask[i]=mask\n",
    "train_tensor_image1=copy(train_tensor_image)\n",
    "train_tensor_mask1=copy(train_tensor_mask)\n",
    "\n",
    "for aug in range(9):\n",
    "    train_tensor_image1=torch.cat([train_tensor_image1,train_tensor_image], dim=0)\n",
    "    train_tensor_mask1=torch.cat([train_tensor_mask1,train_tensor_mask], dim=0)\n",
    "\n",
    "test_tensor_image=torch.empty(len(test_image_list),3,512,512)\n",
    "test_tensor_mask=torch.empty(len(test_mask_list),1,512,512)\n",
    "tf = ToTensor()\n",
    "for i in range(len(test_image_list)):\n",
    "    image=tf(Image.open(test_image_list[i]))/255\n",
    "    mask=tf(Image.open(test_mask_list[i]).convert(\"L\"))/255\n",
    "    test_tensor_image[i]=image\n",
    "    test_tensor_mask[i]=mask\n",
    "test_tensor_image1=copy(test_tensor_image)\n",
    "test_tensor_mask1=copy(test_tensor_mask)\n",
    "\n",
    "for aug in range(4):\n",
    "    test_tensor_image1=torch.cat([test_tensor_image1,test_tensor_image], dim=0)\n",
    "    test_tensor_mask1=torch.cat([test_tensor_mask1,test_tensor_mask], dim=0)\n",
    "    \n",
    "\n",
    "train_dataset=CustomDataset(train_tensor_image1,train_tensor_mask1)\n",
    "test_dataset=CustomDataset(test_tensor_image1 ,test_tensor_mask1)\n",
    "dataset_size = len(test_dataset)\n",
    "test_size = int(dataset_size * 0.5)\n",
    "validation_size = dataset_size-test_size\n",
    "validation_dataset, test_dataset = random_split(test_dataset, [validation_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNetUNet                               [16, 1, 512, 512]         513,000\n",
       "├─Sequential: 1-1                        [16, 64, 512, 512]        --\n",
       "│    └─Conv2d: 2-1                       [16, 64, 512, 512]        1,792\n",
       "│    └─ReLU: 2-2                         [16, 64, 512, 512]        --\n",
       "├─Sequential: 1-2                        [16, 64, 512, 512]        --\n",
       "│    └─Conv2d: 2-3                       [16, 64, 512, 512]        36,928\n",
       "│    └─ReLU: 2-4                         [16, 64, 512, 512]        --\n",
       "├─Sequential: 1-3                        [16, 64, 256, 256]        --\n",
       "│    └─Conv2d: 2-5                       [16, 64, 256, 256]        9,408\n",
       "│    └─BatchNorm2d: 2-6                  [16, 64, 256, 256]        128\n",
       "│    └─ReLU: 2-7                         [16, 64, 256, 256]        --\n",
       "├─Sequential: 1-4                        [16, 64, 128, 128]        --\n",
       "│    └─MaxPool2d: 2-8                    [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-9                   [16, 64, 128, 128]        --\n",
       "│    │    └─BasicBlock: 3-1              [16, 64, 128, 128]        73,984\n",
       "│    │    └─BasicBlock: 3-2              [16, 64, 128, 128]        73,984\n",
       "├─Sequential: 1-5                        [16, 128, 64, 64]         --\n",
       "│    └─BasicBlock: 2-10                  [16, 128, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-3                  [16, 128, 64, 64]         73,728\n",
       "│    │    └─BatchNorm2d: 3-4             [16, 128, 64, 64]         256\n",
       "│    │    └─ReLU: 3-5                    [16, 128, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-6                  [16, 128, 64, 64]         147,456\n",
       "│    │    └─BatchNorm2d: 3-7             [16, 128, 64, 64]         256\n",
       "│    │    └─Sequential: 3-8              [16, 128, 64, 64]         8,448\n",
       "│    │    └─ReLU: 3-9                    [16, 128, 64, 64]         --\n",
       "│    └─BasicBlock: 2-11                  [16, 128, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-10                 [16, 128, 64, 64]         147,456\n",
       "│    │    └─BatchNorm2d: 3-11            [16, 128, 64, 64]         256\n",
       "│    │    └─ReLU: 3-12                   [16, 128, 64, 64]         --\n",
       "│    │    └─Conv2d: 3-13                 [16, 128, 64, 64]         147,456\n",
       "│    │    └─BatchNorm2d: 3-14            [16, 128, 64, 64]         256\n",
       "│    │    └─ReLU: 3-15                   [16, 128, 64, 64]         --\n",
       "├─Sequential: 1-6                        [16, 256, 32, 32]         --\n",
       "│    └─BasicBlock: 2-12                  [16, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-16                 [16, 256, 32, 32]         294,912\n",
       "│    │    └─BatchNorm2d: 3-17            [16, 256, 32, 32]         512\n",
       "│    │    └─ReLU: 3-18                   [16, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-19                 [16, 256, 32, 32]         589,824\n",
       "│    │    └─BatchNorm2d: 3-20            [16, 256, 32, 32]         512\n",
       "│    │    └─Sequential: 3-21             [16, 256, 32, 32]         33,280\n",
       "│    │    └─ReLU: 3-22                   [16, 256, 32, 32]         --\n",
       "│    └─BasicBlock: 2-13                  [16, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-23                 [16, 256, 32, 32]         589,824\n",
       "│    │    └─BatchNorm2d: 3-24            [16, 256, 32, 32]         512\n",
       "│    │    └─ReLU: 3-25                   [16, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-26                 [16, 256, 32, 32]         589,824\n",
       "│    │    └─BatchNorm2d: 3-27            [16, 256, 32, 32]         512\n",
       "│    │    └─ReLU: 3-28                   [16, 256, 32, 32]         --\n",
       "├─Sequential: 1-7                        [16, 512, 16, 16]         --\n",
       "│    └─BasicBlock: 2-14                  [16, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-29                 [16, 512, 16, 16]         1,179,648\n",
       "│    │    └─BatchNorm2d: 3-30            [16, 512, 16, 16]         1,024\n",
       "│    │    └─ReLU: 3-31                   [16, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-32                 [16, 512, 16, 16]         2,359,296\n",
       "│    │    └─BatchNorm2d: 3-33            [16, 512, 16, 16]         1,024\n",
       "│    │    └─Sequential: 3-34             [16, 512, 16, 16]         132,096\n",
       "│    │    └─ReLU: 3-35                   [16, 512, 16, 16]         --\n",
       "│    └─BasicBlock: 2-15                  [16, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-36                 [16, 512, 16, 16]         2,359,296\n",
       "│    │    └─BatchNorm2d: 3-37            [16, 512, 16, 16]         1,024\n",
       "│    │    └─ReLU: 3-38                   [16, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-39                 [16, 512, 16, 16]         2,359,296\n",
       "│    │    └─BatchNorm2d: 3-40            [16, 512, 16, 16]         1,024\n",
       "│    │    └─ReLU: 3-41                   [16, 512, 16, 16]         --\n",
       "├─Sequential: 1-8                        [16, 512, 16, 16]         --\n",
       "│    └─Conv2d: 2-16                      [16, 512, 16, 16]         262,656\n",
       "│    └─ReLU: 2-17                        [16, 512, 16, 16]         --\n",
       "├─Upsample: 1-9                          [16, 512, 32, 32]         --\n",
       "├─Sequential: 1-10                       [16, 256, 32, 32]         --\n",
       "│    └─Conv2d: 2-18                      [16, 256, 32, 32]         65,792\n",
       "│    └─ReLU: 2-19                        [16, 256, 32, 32]         --\n",
       "├─Sequential: 1-11                       [16, 512, 32, 32]         --\n",
       "│    └─Conv2d: 2-20                      [16, 512, 32, 32]         3,539,456\n",
       "│    └─ReLU: 2-21                        [16, 512, 32, 32]         --\n",
       "├─Upsample: 1-12                         [16, 512, 64, 64]         --\n",
       "├─Sequential: 1-13                       [16, 128, 64, 64]         --\n",
       "│    └─Conv2d: 2-22                      [16, 128, 64, 64]         16,512\n",
       "│    └─ReLU: 2-23                        [16, 128, 64, 64]         --\n",
       "├─Sequential: 1-14                       [16, 256, 64, 64]         --\n",
       "│    └─Conv2d: 2-24                      [16, 256, 64, 64]         1,474,816\n",
       "│    └─ReLU: 2-25                        [16, 256, 64, 64]         --\n",
       "├─Upsample: 1-15                         [16, 256, 128, 128]       --\n",
       "├─Sequential: 1-16                       [16, 64, 128, 128]        --\n",
       "│    └─Conv2d: 2-26                      [16, 64, 128, 128]        4,160\n",
       "│    └─ReLU: 2-27                        [16, 64, 128, 128]        --\n",
       "├─Sequential: 1-17                       [16, 256, 128, 128]       --\n",
       "│    └─Conv2d: 2-28                      [16, 256, 128, 128]       737,536\n",
       "│    └─ReLU: 2-29                        [16, 256, 128, 128]       --\n",
       "├─Upsample: 1-18                         [16, 256, 256, 256]       --\n",
       "├─Sequential: 1-19                       [16, 64, 256, 256]        --\n",
       "│    └─Conv2d: 2-30                      [16, 64, 256, 256]        4,160\n",
       "│    └─ReLU: 2-31                        [16, 64, 256, 256]        --\n",
       "├─Sequential: 1-20                       [16, 128, 256, 256]       --\n",
       "│    └─Conv2d: 2-32                      [16, 128, 256, 256]       368,768\n",
       "│    └─ReLU: 2-33                        [16, 128, 256, 256]       --\n",
       "├─Upsample: 1-21                         [16, 128, 512, 512]       --\n",
       "├─Sequential: 1-22                       [16, 64, 512, 512]        --\n",
       "│    └─Conv2d: 2-34                      [16, 64, 512, 512]        110,656\n",
       "│    └─ReLU: 2-35                        [16, 64, 512, 512]        --\n",
       "├─Conv2d: 1-23                           [16, 1, 512, 512]         65\n",
       "==========================================================================================\n",
       "Total params: 18,312,809\n",
       "Trainable params: 18,312,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.52\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 12398.36\n",
       "Params size (MB): 71.20\n",
       "Estimated Total Size (MB): 12519.89\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "  return nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "    nn.ReLU(inplace=True),\n",
    "  )\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "  def __init__(self, n_class):\n",
    "    super().__init__()\n",
    "\n",
    "    self.base_model = torchvision.models.resnet18(pretrained=True)\n",
    "    self.base_layers = list(self.base_model.children())\n",
    "\n",
    "    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "    self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "    self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "    self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "    self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "    self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "    self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "    self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "    self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "  def forward(self, input):\n",
    "    x_original = self.conv_original_size0(input)\n",
    "    x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "    layer0 = self.layer0(input)\n",
    "    layer1 = self.layer1(layer0)\n",
    "    layer2 = self.layer2(layer1)\n",
    "    layer3 = self.layer3(layer2)\n",
    "    layer4 = self.layer4(layer3)\n",
    "\n",
    "    layer4 = self.layer4_1x1(layer4)\n",
    "    x = self.upsample(layer4)\n",
    "    layer3 = self.layer3_1x1(layer3)\n",
    "    x = torch.cat([x, layer3], dim=1)\n",
    "    x = self.conv_up3(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    layer2 = self.layer2_1x1(layer2)\n",
    "    x = torch.cat([x, layer2], dim=1)\n",
    "    x = self.conv_up2(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    layer1 = self.layer1_1x1(layer1)\n",
    "    x = torch.cat([x, layer1], dim=1)\n",
    "    x = self.conv_up1(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    layer0 = self.layer0_1x1(layer0)\n",
    "    x = torch.cat([x, layer0], dim=1)\n",
    "    x = self.conv_up0(x)\n",
    "\n",
    "    x = self.upsample(x)\n",
    "    x = torch.cat([x, x_original], dim=1)\n",
    "    x = self.conv_original_size2(x)\n",
    "\n",
    "    out = self.conv_last(x)\n",
    "\n",
    "    return out\n",
    "model = ResNetUNet(1)\n",
    "model = model.to(device)\n",
    "summary(model,(batch_size,3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../../model/1-cycle.pth\"\n",
    "\n",
    "def diceloss(pred, target):\n",
    "    smooth = 1.\n",
    "    iflat = pred.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    A_sum = torch.sum(iflat * iflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = diceloss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6788660c0af4812b96bbf7a8594fe1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e698108860424785bc83401db9a18d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d484be8f4384aa1a8c428490d0b1fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfed7e000244c96831c0d54e6dc2191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2251599c05464585f424de68a5be94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2750a801a79c4edc82d7847f24ed2c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf22daf093b9479a89fa824a7b86191e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4617ad1e2a407baadf5e917236eb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a557dc2c7c741728aa5a992ba51ec7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab19f0a9a7e4ee2af8dc785e40e0ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138d667baf5d4fac8a316c97aad10bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5925adeb62e477faf881d10839a7ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecf5b317b6040fdbb60f73ece42464e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6701c4902cea47949ecfc2ae02aaa851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe437ba78e8d4775b61f40e7d0469ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e319047e44467195c57caa7c0e1e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c891f6b1b8484943818508db261d5e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e326dfd41cf54cef9aa96fd9d7ad851a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c969dd6ccde44f7a899ee7957e1aa2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/62 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cf488a58784dadae5b227c73ff1852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/7 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test prediction dice score: 0.688202\n"
     ]
    }
   ],
   "source": [
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "for l in model.base_layers:\n",
    "      for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "metrics = defaultdict(float)\n",
    "for epoch in range(10):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = calc_loss(predict, y,metrics) # cost 구함\n",
    "        acc=1-calc_loss(predict, y,metrics)\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        train.set_description(f\"epoch: {epoch+1}/{10} Step: {count+1} dice_loss : {running_loss/count:.4f} dice_score: {acc_loss/count:.4f}\")\n",
    "        train_loss_list.append((running_loss/count))\n",
    "        train_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "#validation\n",
    "    val=tqdm(validation_dataloader)\n",
    "    model.eval()\n",
    "    count=0\n",
    "    val_running_loss=0.0\n",
    "    acc_loss=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            cost = calc_loss(predict, y,metrics) # cost 구함\n",
    "            acc=1-calc_loss(predict, y,metrics)\n",
    "            val_running_loss+=cost.item()\n",
    "            acc_loss+=acc\n",
    "            val.set_description(f\"Validation epoch: {epoch+1}/{10} Step: {count+1} dice_loss : {val_running_loss/count:.4f}  dice_score: {acc_loss/count:.4f}\")\n",
    "            val_loss_list.append((val_running_loss/count))\n",
    "            val_acc_list.append((acc_loss/count).cpu().detach().numpy())\n",
    "with torch.no_grad():\n",
    "    count=0\n",
    "    test_running_loss=0\n",
    "    acc_loss=0\n",
    "    for x, y in test_dataloader:\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        \n",
    "        predict = model(x).to(device)\n",
    "        cost = calc_loss(predict, y,metrics) # cost 구함\n",
    "        acc=1-calc_loss(predict, y,metrics)\n",
    "        test_running_loss+=cost.item()\n",
    "        acc_loss+=acc\n",
    "print('test prediction dice score: %f'%(acc_loss/count).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
