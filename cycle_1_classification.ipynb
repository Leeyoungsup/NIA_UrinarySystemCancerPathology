{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "import torchmetrics\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image,label):\n",
    "        self.img=image\n",
    "        self.label=label\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tensor=self.img[idx]\n",
    "        label_tensor=self.label[idx]\n",
    "        return image_tensor,label_tensor\n",
    "    \n",
    "negative_image_path='../../data/1-cycle_10%_초기데이터/classification/negative/*.tiff'\n",
    "CIS_image_path='../../data/1-cycle_10%_초기데이터/classification/CIS/*.tiff'\n",
    "positive_image_path='../../data/1-cycle_10%_초기데이터/classification/positive/*.tiff'\n",
    "\n",
    "negative_image_list=glob(negative_image_path)\n",
    "CIS_image_list=glob(negative_image_path)\n",
    "positive_image_list=glob(negative_image_path)\n",
    "\n",
    "negative_tensor_image=torch.empty(len(negative_image_list),3,512,512)\n",
    "negative_tensor_label=torch.zeros(len(negative_image_list),3)\n",
    "CIS_tensor_image=torch.empty(len(CIS_image_list),3,512,512)\n",
    "CIS_tensor_label=torch.zeros(len(CIS_image_list),3)\n",
    "positive_tensor_image=torch.empty(len(positive_image_list),3,512,512)\n",
    "positive_tensor_label=torch.zeros(len(positive_image_list),3)\n",
    "\n",
    "tf = ToTensor()\n",
    "for i in range(len(negative_image_list)):\n",
    "    image=1-tf(Image.open(negative_image_list[i]))/255\n",
    "    negative_tensor_image[i]=image\n",
    "    negative_tensor_label[i][0]=1\n",
    "\n",
    "for i in range(len(CIS_image_list)):\n",
    "    image=1-tf(Image.open(CIS_image_list[i]))/255\n",
    "    CIS_tensor_image[i]=image\n",
    "    CIS_tensor_label[i][1]=1\n",
    "    \n",
    "for i in range(len(positive_image_list)):\n",
    "    image=1-tf(Image.open(positive_image_list[i]))/255\n",
    "    positive_tensor_image[i]=image\n",
    "    positive_tensor_label[i][2]=1\n",
    "\n",
    "\n",
    "\n",
    "train_tensor_image=torch.cat([negative_tensor_image[:40],CIS_tensor_image[:40]], dim=0)\n",
    "train_tensor_image=torch.cat([train_tensor_image,positive_tensor_image[:40]], dim=0)\n",
    "train_tensor_label=torch.cat([negative_tensor_label[:40],CIS_tensor_label[:40]], dim=0)\n",
    "train_tensor_label=torch.cat([train_tensor_label,positive_tensor_label[:40]], dim=0)\n",
    "\n",
    "test_tensor_image=torch.cat([negative_tensor_image[40:],CIS_tensor_image[40:]], dim=0)\n",
    "test_tensor_image=torch.cat([test_tensor_image,positive_tensor_image[40:]], dim=0)\n",
    "test_tensor_label=torch.cat([negative_tensor_label[40:],CIS_tensor_label[40:]], dim=0)\n",
    "test_tensor_label=torch.cat([test_tensor_label,positive_tensor_label[40:]], dim=0)\n",
    "\n",
    "train_tensor_image1=copy(train_tensor_image)\n",
    "train_tensor_label1=copy(train_tensor_label)\n",
    "\n",
    "test_tensor_image1=copy(test_tensor_image)\n",
    "test_tensor_label1=copy(test_tensor_label)\n",
    "for aug in range(8):\n",
    "    test_tensor_image1=torch.cat([test_tensor_image1,test_tensor_image], dim=0)\n",
    "    test_tensor_label1=torch.cat([test_tensor_label1,test_tensor_label], dim=0)\n",
    "    \n",
    "for aug in range(7):\n",
    "    train_tensor_image1=torch.cat([train_tensor_image1,train_tensor_image], dim=0)\n",
    "    train_tensor_label1=torch.cat([train_tensor_label1,train_tensor_label], dim=0)\n",
    "    \n",
    "train_dataset=CustomDataset(train_tensor_image1,train_tensor_label1)\n",
    "test_dataset=CustomDataset(test_tensor_image1 ,test_tensor_label1)\n",
    "dataset_size = len(test_dataset)\n",
    "test_size = int(dataset_size * 0.5)\n",
    "validation_size = dataset_size-test_size\n",
    "validation_dataset, test_dataset = random_split(test_dataset, [validation_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [16, 3]                   --\n",
       "├─Sequential: 1-1                        [16, 64, 128, 128]        --\n",
       "│    └─Conv2d: 2-1                       [16, 64, 256, 256]        9,408\n",
       "│    └─BatchNorm2d: 2-2                  [16, 64, 256, 256]        128\n",
       "│    └─ReLU: 2-3                         [16, 64, 256, 256]        --\n",
       "│    └─MaxPool2d: 2-4                    [16, 64, 128, 128]        --\n",
       "├─Sequential: 1-2                        [16, 256, 128, 128]       --\n",
       "│    └─BottleNeck: 2-5                   [16, 256, 128, 128]       --\n",
       "│    │    └─Sequential: 3-1              [16, 256, 128, 128]       58,112\n",
       "│    │    └─Sequential: 3-2              [16, 256, 128, 128]       16,896\n",
       "│    │    └─ReLU: 3-3                    [16, 256, 128, 128]       --\n",
       "│    └─BottleNeck: 2-6                   [16, 256, 128, 128]       --\n",
       "│    │    └─Sequential: 3-4              [16, 256, 128, 128]       70,400\n",
       "│    │    └─Sequential: 3-5              [16, 256, 128, 128]       --\n",
       "│    │    └─ReLU: 3-6                    [16, 256, 128, 128]       --\n",
       "│    └─BottleNeck: 2-7                   [16, 256, 128, 128]       --\n",
       "│    │    └─Sequential: 3-7              [16, 256, 128, 128]       70,400\n",
       "│    │    └─Sequential: 3-8              [16, 256, 128, 128]       --\n",
       "│    │    └─ReLU: 3-9                    [16, 256, 128, 128]       --\n",
       "├─Sequential: 1-3                        [16, 512, 64, 64]         --\n",
       "│    └─BottleNeck: 2-8                   [16, 512, 64, 64]         --\n",
       "│    │    └─Sequential: 3-10             [16, 512, 64, 64]         247,296\n",
       "│    │    └─Sequential: 3-11             [16, 512, 64, 64]         132,096\n",
       "│    │    └─ReLU: 3-12                   [16, 512, 64, 64]         --\n",
       "│    └─BottleNeck: 2-9                   [16, 512, 64, 64]         --\n",
       "│    │    └─Sequential: 3-13             [16, 512, 64, 64]         280,064\n",
       "│    │    └─Sequential: 3-14             [16, 512, 64, 64]         --\n",
       "│    │    └─ReLU: 3-15                   [16, 512, 64, 64]         --\n",
       "│    └─BottleNeck: 2-10                  [16, 512, 64, 64]         --\n",
       "│    │    └─Sequential: 3-16             [16, 512, 64, 64]         280,064\n",
       "│    │    └─Sequential: 3-17             [16, 512, 64, 64]         --\n",
       "│    │    └─ReLU: 3-18                   [16, 512, 64, 64]         --\n",
       "│    └─BottleNeck: 2-11                  [16, 512, 64, 64]         --\n",
       "│    │    └─Sequential: 3-19             [16, 512, 64, 64]         280,064\n",
       "│    │    └─Sequential: 3-20             [16, 512, 64, 64]         --\n",
       "│    │    └─ReLU: 3-21                   [16, 512, 64, 64]         --\n",
       "├─Sequential: 1-4                        [16, 1024, 32, 32]        --\n",
       "│    └─BottleNeck: 2-12                  [16, 1024, 32, 32]        --\n",
       "│    │    └─Sequential: 3-22             [16, 1024, 32, 32]        986,112\n",
       "│    │    └─Sequential: 3-23             [16, 1024, 32, 32]        526,336\n",
       "│    │    └─ReLU: 3-24                   [16, 1024, 32, 32]        --\n",
       "│    └─BottleNeck: 2-13                  [16, 1024, 32, 32]        --\n",
       "│    │    └─Sequential: 3-25             [16, 1024, 32, 32]        1,117,184\n",
       "│    │    └─Sequential: 3-26             [16, 1024, 32, 32]        --\n",
       "│    │    └─ReLU: 3-27                   [16, 1024, 32, 32]        --\n",
       "│    └─BottleNeck: 2-14                  [16, 1024, 32, 32]        --\n",
       "│    │    └─Sequential: 3-28             [16, 1024, 32, 32]        1,117,184\n",
       "│    │    └─Sequential: 3-29             [16, 1024, 32, 32]        --\n",
       "│    │    └─ReLU: 3-30                   [16, 1024, 32, 32]        --\n",
       "│    └─BottleNeck: 2-15                  [16, 1024, 32, 32]        --\n",
       "│    │    └─Sequential: 3-31             [16, 1024, 32, 32]        1,117,184\n",
       "│    │    └─Sequential: 3-32             [16, 1024, 32, 32]        --\n",
       "│    │    └─ReLU: 3-33                   [16, 1024, 32, 32]        --\n",
       "│    └─BottleNeck: 2-16                  [16, 1024, 32, 32]        --\n",
       "│    │    └─Sequential: 3-34             [16, 1024, 32, 32]        1,117,184\n",
       "│    │    └─Sequential: 3-35             [16, 1024, 32, 32]        --\n",
       "│    │    └─ReLU: 3-36                   [16, 1024, 32, 32]        --\n",
       "│    └─BottleNeck: 2-17                  [16, 1024, 32, 32]        --\n",
       "│    │    └─Sequential: 3-37             [16, 1024, 32, 32]        1,117,184\n",
       "│    │    └─Sequential: 3-38             [16, 1024, 32, 32]        --\n",
       "│    │    └─ReLU: 3-39                   [16, 1024, 32, 32]        --\n",
       "├─Sequential: 1-5                        [16, 2048, 16, 16]        --\n",
       "│    └─BottleNeck: 2-18                  [16, 2048, 16, 16]        --\n",
       "│    │    └─Sequential: 3-40             [16, 2048, 16, 16]        3,938,304\n",
       "│    │    └─Sequential: 3-41             [16, 2048, 16, 16]        2,101,248\n",
       "│    │    └─ReLU: 3-42                   [16, 2048, 16, 16]        --\n",
       "│    └─BottleNeck: 2-19                  [16, 2048, 16, 16]        --\n",
       "│    │    └─Sequential: 3-43             [16, 2048, 16, 16]        4,462,592\n",
       "│    │    └─Sequential: 3-44             [16, 2048, 16, 16]        --\n",
       "│    │    └─ReLU: 3-45                   [16, 2048, 16, 16]        --\n",
       "│    └─BottleNeck: 2-20                  [16, 2048, 16, 16]        --\n",
       "│    │    └─Sequential: 3-46             [16, 2048, 16, 16]        4,462,592\n",
       "│    │    └─Sequential: 3-47             [16, 2048, 16, 16]        --\n",
       "│    │    └─ReLU: 3-48                   [16, 2048, 16, 16]        --\n",
       "├─AdaptiveAvgPool2d: 1-6                 [16, 2048, 1, 1]          --\n",
       "├─Linear: 1-7                            [16, 3]                   6,147\n",
       "==========================================================================================\n",
       "Total params: 23,514,179\n",
       "Trainable params: 23,514,179\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 341.65\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 14864.61\n",
       "Params size (MB): 94.06\n",
       "Estimated Total Size (MB): 15009.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=3, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])\n",
    "\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "model = resnet50()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "summary(model,(batch_size,3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc7b06a11c443d98c2cb0067acd8b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd8ade14149480cbd4183e7161d793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3de0c2f0bd42cf92e6d900d0448e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40195fd58033493a8e28fdcee6eeff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f37376bc3d4d00a5b8cb19b3061749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb82c10207c4870933630116bcdfce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31c8615edfc43c2a2ba848901aa4e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6c6b614e474cfaa5c7ec38f5e864db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dae5614f754310bd022a84d2e900d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346970386fa64e23bced50a205939f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34522a17d9c2417aa7c9fb09b8460ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceaf4c35f3b4135b8c59f42f605b053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3142c5776dea43f38037ca0ce8710540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22519b84937c4be4a96eea2a865f9b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0419aef92ab345b18b4c665440eb25c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048bca69de7d435881e0e17d6c32cdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74622afa6ab246f89042433d0fdcfa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9df3fd9e2246e38f44d7afef5e1fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1a308526354c77b4fbe57bd1e95658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/60 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204eaddf98344ba7b9d07340ce134753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/8 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          정상       0.32      1.00      0.49        41\n",
      "       제자리암종       0.00      0.00      0.00        45\n",
      "      악성(종양)       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.32       128\n",
      "   macro avg       0.11      0.33      0.16       128\n",
      "weighted avg       0.10      0.32      0.16       128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1361017/1533318966.py:75: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = torch.argmax(soft(predict_list), 1).cpu().detach().numpy()\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "\n",
    "MIN_loss=5000\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "val_acc_list=[]\n",
    "soft=nn.Softmax(dim=0)\n",
    "for epoch in range(10):\n",
    "    \n",
    "    train_count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    train=tqdm(train_dataloader)\n",
    "    for x, y in train:\n",
    "        model.train()\n",
    "        y = y.to(device).float()\n",
    "        train_count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = criterion(predict, y) # cost 구함\n",
    "        acc=accuracy(torch.argmax(soft(predict), 1), torch.argmax(y, 1))\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        train.set_description(f\"epoch: {epoch+1}/{10} Step: {train_count+1} loss : {running_loss/train_count:.4f} accuracy: {acc_loss/train_count:.4f}\")\n",
    "    train_loss_list.append((running_loss/train_count))\n",
    "    train_acc_list.append((acc_loss/train_count).cpu().detach().numpy())\n",
    "#validation\n",
    "    model.eval()\n",
    "    val=tqdm(validation_dataloader)\n",
    "    val_count=0\n",
    "    val_running_loss=0.0\n",
    "    val_acc_loss=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in val:\n",
    "            y = y.to(device).float()\n",
    "            val_count+=1\n",
    "            x=x.to(device).float()\n",
    "            \n",
    "            predict = model(x).to(device)\n",
    "            acc=accuracy(torch.argmax(soft(predict), 1), torch.argmax(y, 1))\n",
    "            cost = criterion(predict, y)\n",
    "            val_running_loss+=cost.item()\n",
    "            val_acc_loss+=acc\n",
    "            val.set_description(f\"Validation epoch: {epoch+1}/{10} Step: {val_count+1} loss : {val_running_loss/val_count:.4f}  accuracy: {val_acc_loss/val_count:.4f}\")\n",
    "        \n",
    "            val_loss_list.append((val_running_loss/val_count))\n",
    "            val_acc_list.append((val_acc_loss/val_count).cpu().detach().numpy())\n",
    "            \n",
    "target_names = ['정상', '제자리암종', '악성(종양)']\n",
    "with torch.no_grad():\n",
    "    count=0\n",
    "    test_running_loss=0\n",
    "    acc_loss=0\n",
    "    predict_list=torch.empty(0,3)\n",
    "    y_list=torch.empty(0,3)\n",
    "    for x, y in test_dataloader:\n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        \n",
    "        predict = model(x).to(device)\n",
    "        acc=accuracy(predict, y)\n",
    "        cost = criterion(predict, y)\n",
    "        test_running_loss+=cost.item()\n",
    "        acc_loss+=acc\n",
    "        predict_list=torch.cat([predict_list,predict.cpu()], dim=0)\n",
    "        y_list=torch.cat([y_list,y.cpu()], dim=0)\n",
    "soft=nn.Softmax()\n",
    "y_pred = torch.argmax(soft(predict_list), 1).cpu().detach().numpy()\n",
    "y=torch.argmax(y_list, 1)\n",
    "print(classification_report(y, y_pred, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
